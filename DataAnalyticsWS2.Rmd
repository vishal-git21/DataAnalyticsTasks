---
title: "Worksheet-2"
author: "Vishal Ravishankar"
date: "2023-09-02"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#metadata S. No.: Serial number State/ UT: name of state/union terrirory
in India Fine/Clear - Total Accidents: total accidents per state/UT in
Fine/Clear weather conditions Fine/Clear - Persons Killed: total
fatalities per state/UT in Fine/Clear weather conditions Fine/Clear -
Persons Injured: total injured people per state/UT in Fine/Clear weather
conditions Mist/Foggy - Total Accidents: total accidents per state/UT in
Mist/Foggy weather conditions Mist/ Foggy - Persons Killed: total
fatalities perstate/UT in Mist/Foggy weather conditions Mist/ Foggy -
Persons Injured:total injured people per state/UT in Mist/Foggy weather
conditions Cloudy - Total Accidents: total accidents per state/UT in
Cloudy weather conditions Cloudy - Persons Killed: total fatalities per
state/UT inCloudy weather conditions Cloudy - Persons Injured: total
injured people per state/UT in Cloudy weather conditions Rainy - Total
Accidents: total accidents per state/UT in Rainy weather conditions
Rainy - Persons Killed: total fatalities per state/UT in Rainy weather
conditions Rainy - Persons Injured: total injured people per state/UT in
Rainy weather conditions Snowfall - Total Accidents: total accidents per
state/UT in Snowfall weather conditions Snowfall - Persons Killed:
totalfatalities per state/UT in Snowfall weather conditions Snowfall -
Persons Injured: total injured people per state/UT in Snowfall weather
conditions Hail/Sleet - Total Accidents: total accidents per state/UT in
Hail/Sleet weather conditions Hail/Sleet - Persons Killed: total
fatalities per state/UT in Hail/Sleet weather conditions Hail/Sleet -
Persons Injured: total injured people per state/UT in Hail/Sleet weather
conditions Dust Storm - Total Accidents: total accidents per state/UT in
Dust Storm weather conditions Dust Storm - Persons Killed: total
fatalities per state/UT in Dust Storm weather conditions Dust Storm -
Persons Injured: total injured people per state/UT in Dust Storm weather
conditions Others - Total Accidents: total accidents per state/UT in
Other weather conditions Others - Persons Killed: total fatalities
perstate/UT in Other weather conditions Others - Persons Injured: total
injured people per state/UT in Other weather conditions

```{r}
library(ggpubr)
library(dplyr)
library(ggplot2)

data2=read.csv("road_accidents_india_2016.csv",header=TRUE)
str(data2)
```

#Problem 1 Find the total number of accidents in each state for the year
2016 and display your results. Make sure to display all rows while
printing the dataframe. Print only the necessary columns. (Hint: use the
grep command to help filter out column names).

```{r}
# Initialize empty vectors to store State/UT names and total accidents
state_ut_names <- character(nrow(data2))
total_accidents <- numeric(nrow(data2))

# Iterate through each row in data2 starting from row 1
for (row_index in 1:nrow(data2)) {
  # Extract the values from the specific columns for the current row
  values <- c(
    data2[row_index, "Fine.Clear...Total.Accidents"],
    data2[row_index, "Mist..Foggy...Total.Accidents"],
    data2[row_index, "Cloudy...Total.Accidents"],
    data2[row_index, "Rainy...Total.Accidents"],
    data2[row_index, "Snowfall...Total.Accidents"],
    data2[row_index, "Hail.Sleet...Total.Accidents"],
    data2[row_index, "Dust.Storm...Total.Accidents"],
    data2[row_index, "Others...Total.Accidents"]
  )
  
  # Sum the values for the selected columns
  total_value <- sum(values, na.rm = TRUE)  # Use na.rm = TRUE to handle missing values
  
  # Get the corresponding "State/UT" value for the current row
  state_ut_name <- data2[row_index, "State..UT"]
  
  # Store the State/UT name and total accidents in the vectors
  state_ut_names[row_index] <- state_ut_name
  total_accidents[row_index] <- total_value
}

# Create a bar chart
barplot(total_accidents, 
        names.arg = 1:length(state_ut_names), 
        xlab = "State/UT", 
        ylab = "Total Accidents",
        main = "Total Accidents by State/UT", 
        col = "blue",
        border = "black",
        las=1,
        width=10,
        cex.axis = 0.8,
        cex.names = 0.8)
```

```{r}
acc_cols<-grep("Total.accidents$",colnames(data2),ignore.case=T,value=TRUE)

total_accidents<-data.frame(
  state..ut = data2$State..UT,
  total_acc = rowSums(data2[ ,c(acc_cols)],na.rm=TRUE))

print.data.frame(total_accidents)
```

#problem 1-Inferences: Grep is a built in function used for pattern
matching in character vectors.Here, we are matching it with all columns
having "Total.accidents". we create a data frame total_accidents and sum
the columns which match the pattern with help of row Sum function. na.rm
is set to true so that NA values are ignored without giving errors.Then
we print the whole data frame.

With the bar plot we can infer that s.no.24 i.e Tamil Nadu has highest
Total accidents in 2016.(71k) Lakhswadeep the least i.e. 1 accident in
2016.

#Problem 2 Find the (fatality rate = total number of deaths/total number
of accidents ) in each state. Find out if there is a significant linear
correlation at a significance of α = 0.05 between the fatality rate of a
state and the mist/foggy rate (fraction of total accidents that happen
in mist/foggy conditions). Correlation between two continuous RVs:
Pearson's correlation coefficient. Pearson's correlation coefficient
between two RVs x and y is given by: ρ =Covariance(x, y)/σx\*σy where: ρ
represents the Pearson's correlation coefficient Covariance(x, y) is the
covariance between x and y σx is the standard deviation of x σy is the
standard deviation of y. Plot the fatality rate against the mist/foggy
rate. (Hint: use the ggscatter library to plot a scatterplot with the
confidence interval of the correlation coefficient). Plot the fatality
rate and mist/foggy rate (see this and this for R plot customization).

```{r}
death_cols<-grep("Persons.Killed$",colnames(data2),ignore.case = TRUE,value=TRUE)

total_accidents$total_deaths<-rowSums(data2[ , c(death_cols)])

total_accidents$fatality_rate<-total_accidents$total_deaths/total_accidents$total_acc

total_accidents$miss_rate<-data2$Mist..Foggy...Total.Accidents/total_accidents$total_acc

print.data.frame(total_accidents)
```

```{r}
rho<-cor(total_accidents$fatality_rate,total_accidents$miss_rate,method='pearson')
rho
rho1<-cor.test(total_accidents$fatality_rate,total_accidents$miss_rate,method='pearson')
rho1
```

```{r}
plot(x=total_accidents$fatality_rate,y=total_accidents$miss_rate,col="black",pch=19)
```

```{r}
ggplot(total_accidents, 
       aes(y=total_accidents$miss_rate, 
           x=total_accidents$fatality_rate, 
           alpha=total_accidents$miss_rate, 
           size=total_accidents$fatality_rate, 
           color=total_accidents$miss_rate)) + 
    geom_point()
    
```

#Problem 2-Inferences Null hypothesis-There is no relation between miss
rate and fatality rate. Alternative hypothesis- there is relation
between miss rate and fatality rate. p-value\>alpha(0.05) Failed to
reject null hypothesis. Therefore,There is no relation between miss rate
and fatality rate. With the help of scatter plot also we can tell that
there is no corelation between miss rate and fatality rate.

#Problem 3 Rank the states based on total accidents and total fatalities
(give a rank of 1 to the state that has the highest value of a
property). You are free to use any tie-breaking method for assigning
ranks. Find the Spearman-Rank correlation coefficient between the two
rank columns and determine if there is any statistical significance at a
significance level of α = 0.05. Also test the hypothesis that the
correlation coefficient is at least 0.2.

where: • t represents the t-statistic, • rs is the Spearman-Rank
correlation coefficient, • ρs value of the population correlation
coefficient being tested against, • n is the number of data points in
the sample.

```{r}
total_accidents$rank_total_accidents <- rank(-total_accidents$total_acc, ties.method = "first")
total_accidents$rank_fatality_rate <- rank(-total_accidents$fatality_rate, ties.method = "first")
total_accidents <- total_accidents[order(-total_accidents$rank_total_acc, -total_accidents$rank_fatality_rate), ]
print.data.frame(total_accidents[, c("state..ut", "rank_total_accidents", "rank_fatality_rate")])
```

```{r}
no_data_pts=length(total_accidents$rank_fatality_rate)
rs_0<-cor(total_accidents$rank_total_accidents,total_accidents$rank_fatality_rate,method='spearman')
rs_0.2<-cor(total_accidents$rank_total_accidents,total_accidents$rank_fatality_rate,method='spearman')

alpha<-0.05

Population_cc<-0.2

df<-no_data_pts-2

sd_0<-((1-(rs_0)^2)/(df))^0.5
sd_0.2<-((1-(rs_0.2)^2)/(df))^0.5

t_stat_0<-rs_0/sd_0

t_stat_0.2<-(rs_0.2-Population_cc)/sd_0.2

t_crit_0.2 <- qt(1-alpha, df,lower.tail = FALSE)

t_crit_0 <- qt(1-alpha/2, df)

print('no_data_pts:')
print(no_data_pts)
print("significance level- α:")
print(alpha)
print("degrees of freedom:")
print(df)
print("T_stat_for_0:")
print(t_stat_0)
print("T_crit_0:")
t_crit_0
print("T_stat_atleast_0.2:")
print(t_stat_0.2)
print("T_crit_0.2:")
t_crit_0.2

rs_0<-cor.test(total_accidents$rank_total_accidents,total_accidents$rank_fatality_rate,alternative = "two.sided",method='spearman')
rs_0.2<-cor.test(total_accidents$rank_total_accidents,total_accidents$rank_fatality_rate,alternative = "greater",method='spearman')

rs_0
rs_0.2
```

#Problem 3:Inferences We are first adding two columns to data frame
total accidents with help if rank function. and "-" sign indicates than
we want to rank them in descending order.rank function assign rank based
on the numeric value and stores in a vector. order function arranges
them in specified order.i have used ties method as first. In first
method if any tie happens it breaks by assigning lowest rank to first
occurring data and highest rank to next occurring data. For spear
men-rank correlation coefficient n=number of data points which can be
calculated by nrow() or length() function. degree of freedom for spear
man-rank correlation coefficient is n-2.as both X and Ymean are
parameters so n-2.

Ho(Null Hypothesis)-rho=0;(indicating no monotonic relationship BTW x
and y) Ha(alternate hypothesis)-r!=0;(indicating monotonic relationship
BTW x and y)

P-value is lesser than α. so the relation is statistically significant

rs is negative and close to 0.So we can infer that there is significant
weak monotonic relationship between total accidents rank and fatality
rate rank. negative tells if one increases the other decreases.
tstat=-2.15 tcrit-2.03/2.03(as two tail both values considered)

t_stat_0\<t_crit p-value\<alpha. Reject null hypothesis. there is
monotonic relation between fatality rate rank and total accidents rank.

For at least 0.2

Ho(Null_hypothesis)-less than or equal to 0.2 Ha(Alternative
hypothesis)-greater than 0.2

t_stat_0.2\<t_crit_0.2 p-value\> alpha failed to reject null hypothesis.

#Problem 4 Convert the column Hail.Sleet. . . Total.Accidents to a
binary column as follows. If a hail/sleet accident has occurred in a
state, give that state a value of 1. Otherwise, give it a value of 0.
Once converted, find out if there is a significant correlation between
the hail_accident_occcur binary column created and the number of rainy
total accidents for every state. Calculate the point bi-serial
correlation coefficient between the two columns. (Hint: it is equivalent
to calculating the Pearson correlation between a continuous and a
dichotomous variable. You could also use the ltm package's biserial.cor
function).

```{r}
library(ltm)
total_accidents$hail_binary <- ifelse(data2$Hail.Sleet...Total.Accidents > 0, 1, 0)

#using simple pearson cor.test function
cor.test(data2$Rainy...Total.Accidents,total_accidents$hail_binary)

#using biserial.cor from ltm package
biserial_cor <- biserial.cor(data2$Rainy...Total.Accidents,total_accidents$hail_binary)
biserial_cor
```

#Problem 4:Inferences the bi serial_cor value shows a weak negative
correlation between the continuous value total accidents due to rain and
binary value total accidents due to hail/sleet. bi serial_cor and
cor.test have same magnitude. but cor.test is used for pearsons moment
correlation it assumes both columns to be continuous. the p-value is
greater than the significance level which suggests relationship is very
weak negative and not statistically significant.

#Problem 5 Similar to in Problem 4, create a binary column to represent
whether a dust storm accident has occurred in a state (1 = occurred, 0 =
not occurred). Convert the two columns into a contingency table.
Calculate the phi coefficient of the two tables. (Hint: use the psych
package).

```{r}
library(psych)
total_accidents$dust_storm_accidents_binary <- ifelse(data2$Dust.Storm...Total.Accidents > 0, 1, 0)
print(total_accidents$dust_storm_accidents_binary)
contingency_table <- table(total_accidents$dust_storm_accidents_binary, total_accidents$hail_binary)
print(contingency_table)
phi_coefficient <- phi(contingency_table)
print(phi_coefficient)
```

#Problem 5:Inferences We are adding a new data frame
dust_storm_accidents_binary to total_accidents with help of if else
function, if the data is \>0 it takes 1 as new data and if not 0.
contingency table can be created by table function in R with two
arguments x and y. it is usually a 2X2 table each data corresponds to
number of possible combination of x and y. With help of psych library we
calculate phi coefficient. As phi coefficient is 0.62 which shows a
strong positive correlation.Most of the data falls along the positive
cells.

#Problem 6 Read about correlation on this website and analyze the effect
of sample size on correlation coefficients and spurious correlation. Are
correlation coefficients affected by outliers ?

#Problem 6 Inferences:

#Problem -7 Look at these plots and answer What problems do they have?
How do they affect correlation analysis?

#Problem 7: Infereneces i.As iphone sales increases over years, death
due to falling down stairs also increases.It shows that they are
positively correlated but correlation doesn't mean causation. iphone are
not cause for death of people, it may be due to urbanization or other
any other factors. It is spurious correlation. ii.As per capita
consumption of high-fructose corn syrup decreases, people spending on
admission to spectator sports decreases. It shows negative correlation
but it's not the cause.It is spurious correlation, people when started
spending on admission to spectator sports became more aware about the
ill effects of intake of high-fructose corn syrup.but we cannot say they
are correlated. iii.Graph shows that decrease in sales of new cars also
decreases visitors to universal Orlando's island of adventure.It is
spurious correlation. iv.Increase in ebay's total gross merchandise
volume also increases Total Black Friday online revenue.This correlation
is due to many factors like increased sales, higher customer engagement
and effective marketing.They are spuriously correlated and there are
many factors which effect both attributes. v.This graph shows how its
customers under 40 and over 40 have same trends of shopping in the whole
year. but people under 40 spend more compared to people over 40. but
they are not correlated it is a spurious correlation.
